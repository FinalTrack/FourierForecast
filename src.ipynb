{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9120259,"sourceType":"datasetVersion","datasetId":5505506}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy.fft import fft, ifft\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.cuda.amp import autocast, GradScaler\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-08-11T20:43:57.737455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(file_path, column_names, input_size, output_size, skip):\n    df = pd.read_csv(file_path)\n    data = df[column_names].values\n    scaler = StandardScaler()\n    normalized = data\n\n    inputs = []\n    outputs = []\n\n    for i in range(normalized.shape[1]):\n        col_data = normalized[:, i] \n        for j in range(0, len(col_data) - input_size - output_size + 1, skip):\n            input_window = col_data[j:j + input_size]\n            output_window = col_data[j + input_size:j + input_size + output_size]\n            inputs.append(input_window)\n            outputs.append(output_window)\n\n    inputs = np.array(inputs)\n    outputs = np.array(outputs)\n    \n    return inputs, outputs\n\ntrain_inputs, train_outputs = preprocess('/kaggle/input/electricity/sample.csv', ['column1', 'column2', 'column3'], 3, 3, 2)\n\nprint(\"Train Inputs:\\n\", train_inputs)\nprint(\"Train Outputs:\\n\", train_outputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef apply_transform(signal):\n    frequency_domain = np.fft.fft(signal, axis=1)\n    magnitude = np.abs(frequency_domain) \n    phase = np.angle(frequency_domain)  \n    combined = np.concatenate((magnitude, phase), axis=1)\n    return combined\n\ndef apply_inverse(combined):\n    half_size = combined.shape[1] // 2\n    magnitude = combined[:, :half_size]\n    phase = combined[:, half_size:]\n    real_part = magnitude * np.cos(phase)\n    imag_part = magnitude * np.sin(phase)\n    complex_signal = real_part + 1j * imag_part\n    time_domain_signal = np.fft.ifft(complex_signal, axis=1)\n    return time_domain_signal.real\n\n\ntmp = apply_transform(train_outputs)\nprint(tmp)\nprint(apply_inverse(tmp))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FullyConnectedNN(nn.Module):\n    def __init__(self, input_size, output_size, hidden_layers, hidden_units):\n        super(FullyConnectedNN, self).__init__()\n        \n        self.input_size = input_size\n        self.output_size = output_size\n        self.hidden_layers = hidden_layers\n        self.hidden_units = hidden_units\n        \n        layers = []\n\n        layers.append(nn.Linear(self.input_size, self.hidden_units))\n        layers.append(nn.ReLU())\n\n        for _ in range(self.hidden_layers - 1):\n            layers.append(nn.Linear(self.hidden_units, self.hidden_units))\n            layers.append(nn.ReLU())\n\n        layers.append(nn.Linear(self.hidden_units, self.output_size))\n\n        self.model = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.model(x)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, train_inputs, train_outputs, val_inputs, val_outputs, num_epochs=20, learning_rate=0.001, batch_size=32):\n\n    criterion = nn.MSELoss()  \n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n    train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_inputs).float(), torch.tensor(train_outputs).float())\n    val_dataset = torch.utils.data.TensorDataset(torch.tensor(val_inputs).float(), torch.tensor(val_outputs).float())\n    \n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n    \n    model.to(device)\n    \n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0.0\n        \n        for inputs, targets in train_loader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            \n            optimizer.zero_grad()  \n            outputs = model(inputs)  \n            loss = criterion(outputs, targets) \n            loss.backward()  \n            optimizer.step()  \n            \n            train_loss += loss.item() * inputs.size(0)\n        \n        train_loss /= len(train_loader.dataset)\n        \n        model.eval()\n        val_loss = 0.0\n        with torch.no_grad():\n            for inputs, targets in val_loader:\n                inputs, targets = inputs.to(device), targets.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n                val_loss += loss.item() * inputs.size(0)\n        \n        val_loss /= len(val_loader.dataset)\n        \n        if epoch % 5 == 0:\n            print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, inputs):\n    model.eval()\n    inputs = torch.tensor(inputs).float().to(device)\n    \n    with torch.no_grad():  \n        outputs = model(inputs)  \n    outputs = outputs.cpu().numpy()\n    return outputs\n\ndef measure_mse(actual, predicted):\n    mse = mean_squared_error(actual, predicted)\n    return mse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pipeline():\n    #Read and preprocess CSV files\n    C = 512\n    L = 96\n    skip = 10\n    input_data, output_data = preprocess('/kaggle/input/electricity/ETTm1.csv', ['HUFL', 'HULL', 'MUFL', 'MULL'], C, L, skip)\n    test_inputs, test_outputs = preprocess('/kaggle/input/electricity/ETTm1.csv', ['LUFL', 'LULL'], C, L, skip)\n    train_inputs, val_inputs, train_outputs, val_outputs = train_test_split(input_data, output_data, test_size=0.2, random_state=42)\n    \n    print(\"Train Inputs Shape:\", train_inputs.shape)\n    print(\"Validation Inputs Shape:\", val_inputs.shape)\n    print(\"Test Inputs Shape:\", test_inputs.shape)\n    print(\"Train Outputs Shape:\", train_outputs.shape)\n    print(\"Validation Outputs Shape:\", val_outputs.shape)\n    print(\"Test Outputs Shape:\", test_outputs.shape)\n\n    \n\n    #Calculate the attribute vectors for all the train outputs\n    train_outputs_attr = apply_transform(train_outputs)\n    val_outputs_attr = apply_transform(val_outputs)\n    test_outputs_attr = apply_transform(test_outputs)\n    \n    # Initialize the model\n    model = FullyConnectedNN(C, 2*L, 5, 128)\n    \n    # Train the model\n    print(\"Training\")\n    train_model(model, train_inputs, train_outputs_attr, val_inputs, val_outputs_attr, 50)\n\n    #Training Loss\n    print('\\nTraining Losses:')\n    train_predict = predict(model, train_inputs)\n    val_predict = predict(model, val_inputs)\n    test_predict = predict(model, test_inputs)\n    \n    mse = measure_mse(train_predict, train_outputs_attr)\n    print(f'Train MSE: {mse:.4f}')\n    mse = measure_mse(val_predict, val_outputs_attr)\n    print(f'Validation MSE: {mse:.4f}')\n    mse = measure_mse(test_predict, test_outputs_attr)\n    print(f'Test MSE: {mse:.4f}')\n    \n\n    #Apply inverse DTFT on the predicted outputs to get back in time domain\n    train_result = apply_inverse(train_predict)\n    val_result = apply_inverse(val_predict)\n    test_result = apply_inverse(test_predict)\n    \n    print('\\nEvalation Losses:')\n    mse = measure_mse(train_result, train_outputs)\n    print(f'Train MSE: {mse:.4f}')\n    mse = measure_mse(val_result, val_outputs)\n    print(f'Validation MSE: {mse:.4f}')\n    mse = measure_mse(test_result, test_outputs)\n    print(f'Test MSE: {mse:.4f}')\n\n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"\\nTotal number of parameters: {total_params}\")\n \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\npipeline()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
