{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9120259,"sourceType":"datasetVersion","datasetId":5505506}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy.fft import fft, ifft\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset","metadata":{"execution":{"iopub.status.busy":"2024-08-09T10:31:00.543816Z","iopub.execute_input":"2024-08-09T10:31:00.544188Z","iopub.status.idle":"2024-08-09T10:31:00.549727Z","shell.execute_reply.started":"2024-08-09T10:31:00.544158Z","shell.execute_reply":"2024-08-09T10:31:00.548794Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def preprocess(file_path, column_names, input_size, output_size):\n    df = pd.read_csv(file_path)\n    data = df[column_names].values\n    scaler = StandardScaler()\n    normalized = scaler.fit_transform(data)\n    \n    inputs = []\n    outputs = []\n    \n    for i in range(normalized.shape[1]):\n        col_data = normalized[:, i]  \n        num_windows = len(col_data) // (input_size + output_size)\n        \n        for j in range(num_windows):\n            start_idx = j * (input_size + output_size)\n            end_idx = start_idx + input_size\n            input_window = col_data[start_idx:end_idx]\n            output_window = col_data[end_idx:end_idx + output_size]\n            inputs.append(input_window)\n            outputs.append(output_window)\n            \n    inputs = np.array(inputs)\n    outputs = np.array(outputs)\n    \n    return inputs, outputs\n\ntrain_inputs, train_outputs = preprocess('/kaggle/input/electricity/sample.csv', ['column1', 'column2', 'column3'], 3, 2)\n\nprint(\"Train Inputs:\\n\", train_inputs)\nprint(\"Train Outputs:\\n\", train_outputs)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T10:31:09.161935Z","iopub.execute_input":"2024-08-09T10:31:09.162626Z","iopub.status.idle":"2024-08-09T10:31:09.183160Z","shell.execute_reply.started":"2024-08-09T10:31:09.162592Z","shell.execute_reply":"2024-08-09T10:31:09.182172Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Train Inputs:\n [[-1.5666989  -1.21854359 -0.87038828]\n [ 0.17407766  0.52223297  0.87038828]\n [-1.5666989  -1.21854359 -0.87038828]\n [ 0.17407766  0.52223297  0.87038828]\n [-1.5666989  -1.21854359 -0.87038828]\n [ 0.17407766  0.52223297  0.87038828]]\nTrain Outputs:\n [[-0.52223297 -0.17407766]\n [ 1.21854359  1.5666989 ]\n [-0.52223297 -0.17407766]\n [ 1.21854359  1.5666989 ]\n [-0.52223297 -0.17407766]\n [ 1.21854359  1.5666989 ]]\n","output_type":"stream"}]},{"cell_type":"code","source":"def apply_transform(signal):\n    frequency_domain = np.fft.fft(signal, axis=1) \n    real_part = frequency_domain.real\n    imag_part = frequency_domain.imag\n    combined = np.concatenate((real_part, imag_part), axis=1)\n    return combined\n\ndef apply_inverse(combined):\n    half_size = combined.shape[1] // 2\n    real_part = combined[:, :half_size]\n    imag_part = combined[:, half_size:]\n    complex_signal = real_part + 1j * imag_part\n    time_domain_signal = np.fft.ifft(complex_signal, axis=1)\n    return time_domain_signal.real\n\ntmp = apply_transform(train_outputs)\nprint(tmp)\nprint(apply_inverse(tmp))","metadata":{"execution":{"iopub.status.busy":"2024-08-09T10:32:18.812517Z","iopub.execute_input":"2024-08-09T10:32:18.813194Z","iopub.status.idle":"2024-08-09T10:32:18.821631Z","shell.execute_reply.started":"2024-08-09T10:32:18.813163Z","shell.execute_reply":"2024-08-09T10:32:18.820636Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[[-0.69631062 -0.34815531  0.          0.        ]\n [ 2.7852425  -0.34815531  0.          0.        ]\n [-0.69631062 -0.34815531  0.          0.        ]\n [ 2.7852425  -0.34815531  0.          0.        ]\n [-0.69631062 -0.34815531  0.          0.        ]\n [ 2.7852425  -0.34815531  0.          0.        ]]\n[[-0.52223297 -0.17407766]\n [ 1.21854359  1.5666989 ]\n [-0.52223297 -0.17407766]\n [ 1.21854359  1.5666989 ]\n [-0.52223297 -0.17407766]\n [ 1.21854359  1.5666989 ]]\n","output_type":"stream"}]},{"cell_type":"code","source":"class FullyConnectedNN(nn.Module):\n    def __init__(self, input_size, output_size, hidden_layers, hidden_units):\n        super(FullyConnectedNN, self).__init__()\n        \n        self.input_size = input_size\n        self.output_size = output_size\n        self.hidden_layers = hidden_layers\n        self.hidden_units = hidden_units\n        \n        layers = []\n\n        layers.append(nn.Linear(self.input_size, self.hidden_units))\n        layers.append(nn.ReLU())\n\n        for _ in range(self.hidden_layers - 1):\n            layers.append(nn.Linear(self.hidden_units, self.hidden_units))\n            layers.append(nn.ReLU())\n\n        layers.append(nn.Linear(self.hidden_units, self.output_size))\n\n        self.model = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.model(x)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-09T10:35:22.515439Z","iopub.execute_input":"2024-08-09T10:35:22.516198Z","iopub.status.idle":"2024-08-09T10:35:22.523774Z","shell.execute_reply.started":"2024-08-09T10:35:22.516171Z","shell.execute_reply":"2024-08-09T10:35:22.522864Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def train_model(model, train_inputs, train_outputs, val_inputs, val_outputs, num_epochs=20, learning_rate=0.001, batch_size=32):\n\n    criterion = nn.MSELoss()  \n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n    train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_inputs).float(), torch.tensor(train_outputs).float())\n    val_dataset = torch.utils.data.TensorDataset(torch.tensor(val_inputs).float(), torch.tensor(val_outputs).float())\n    \n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n    \n    model.to(device)\n    \n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0.0\n        \n        for inputs, targets in train_loader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            \n            optimizer.zero_grad()  \n            outputs = model(inputs)  \n            loss = criterion(outputs, targets) \n            loss.backward()  \n            optimizer.step()  \n            \n            train_loss += loss.item() * inputs.size(0)\n        \n        train_loss /= len(train_loader.dataset)\n        \n        model.eval()\n        val_loss = 0.0\n        with torch.no_grad():\n            for inputs, targets in val_loader:\n                inputs, targets = inputs.to(device), targets.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n                val_loss += loss.item() * inputs.size(0)\n        \n        val_loss /= len(val_loader.dataset)\n        \n        if epoch % 5 == 0:\n            print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-09T10:40:39.356836Z","iopub.execute_input":"2024-08-09T10:40:39.357739Z","iopub.status.idle":"2024-08-09T10:40:39.369131Z","shell.execute_reply.started":"2024-08-09T10:40:39.357705Z","shell.execute_reply":"2024-08-09T10:40:39.367983Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def predict(model, inputs):\n    model.eval()\n    inputs = torch.tensor(inputs).float().to(device)\n    \n    with torch.no_grad():  \n        outputs = model(inputs)  \n    outputs = outputs.cpu().numpy()\n    return outputs\n\ndef measure_mse(actual, predicted):\n    mse = mean_squared_error(actual, predicted)\n    return mse","metadata":{"execution":{"iopub.status.busy":"2024-08-09T10:35:35.918698Z","iopub.execute_input":"2024-08-09T10:35:35.919053Z","iopub.status.idle":"2024-08-09T10:35:35.924640Z","shell.execute_reply.started":"2024-08-09T10:35:35.919023Z","shell.execute_reply":"2024-08-09T10:35:35.923730Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def pipeline():\n    #Read and preprocess CSV files\n    C = 1000\n    L = 50\n    train_inputs, train_outputs = preprocess('/kaggle/input/electricity/ETTm1.csv', ['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL'], C, L)\n    val_inputs, val_outputs = preprocess('/kaggle/input/electricity/ETTm1.csv', ['LULL'], C, L)\n    test_inputs, test_outputs = preprocess('/kaggle/input/electricity/ETTm1.csv', ['OT'], C, L)\n\n    #Calculate the attribute vectors for all the train outputs\n    train_outputs_attr = apply_transform(train_outputs)\n    val_outputs_attr = apply_transform(val_outputs)\n    \n    # Initialize the model\n    model = FullyConnectedNN(C, 2*L, 5, 128)\n    \n    # Train the model\n    train_model(model, train_inputs, train_outputs_attr, val_inputs, val_outputs_attr, 100)\n\n    #Apply the model to make inferences on the test data inputs\n    predicted_outputs = predict(model, test_inputs)\n\n    #Apply inverse DTFT on the predicted outputs to get back in time domain\n    result = apply_inverse(predicted_outputs)\n\n    #Measure MSE between predicted and actual outputs\n    mse = measure_mse(test_outputs, result)\n    print(f'Average MSE: {mse:.4f}')\n    print(result)\n    print(test_outputs)\n \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\npipeline()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T10:47:02.213617Z","iopub.execute_input":"2024-08-09T10:47:02.214433Z","iopub.status.idle":"2024-08-09T10:47:05.513760Z","shell.execute_reply.started":"2024-08-09T10:47:02.214397Z","shell.execute_reply":"2024-08-09T10:47:05.512554Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Using device: cuda\nEpoch 1/100, Training Loss: 22.2620, Validation Loss: 22.5418\nEpoch 6/100, Training Loss: 9.4286, Validation Loss: 6.1188\nEpoch 11/100, Training Loss: 6.4682, Validation Loss: 6.3694\nEpoch 16/100, Training Loss: 5.0529, Validation Loss: 7.7710\nEpoch 21/100, Training Loss: 3.5383, Validation Loss: 6.7647\nEpoch 26/100, Training Loss: 2.9137, Validation Loss: 6.7992\nEpoch 31/100, Training Loss: 2.2711, Validation Loss: 7.5745\nEpoch 36/100, Training Loss: 2.1567, Validation Loss: 7.0464\nEpoch 41/100, Training Loss: 1.9291, Validation Loss: 6.9409\nEpoch 46/100, Training Loss: 2.7101, Validation Loss: 7.8915\nEpoch 51/100, Training Loss: 1.6516, Validation Loss: 6.9124\nEpoch 56/100, Training Loss: 1.4637, Validation Loss: 6.6464\nEpoch 61/100, Training Loss: 1.5834, Validation Loss: 6.7873\nEpoch 66/100, Training Loss: 1.2970, Validation Loss: 6.4707\nEpoch 71/100, Training Loss: 1.2275, Validation Loss: 6.5852\nEpoch 76/100, Training Loss: 1.3201, Validation Loss: 6.5520\nEpoch 81/100, Training Loss: 1.1775, Validation Loss: 6.3674\nEpoch 86/100, Training Loss: 1.1580, Validation Loss: 6.2897\nEpoch 91/100, Training Loss: 1.1206, Validation Loss: 6.4368\nEpoch 96/100, Training Loss: 1.2211, Validation Loss: 6.6694\nAverage MSE: 0.1012\n[[ 1.91240896  1.9410848   1.86442827 ...  1.1835039   1.22275401\n   1.22626692]\n [ 2.5034257   2.55659524  2.77965669 ...  1.59358922  1.60022613\n   1.71343572]\n [ 2.4699242   2.4724739   2.56999835 ...  2.0028262   2.15522485\n   2.25031266]\n ...\n [-0.41526061 -0.42761637 -0.36712893 ... -0.49195161 -0.45603856\n  -0.50938965]\n [-0.58412923 -0.60854251 -0.54661329 ... -0.58759231 -0.53836871\n  -0.57792265]\n [-0.62984603 -0.63784395 -0.60305751 ... -0.34983652 -0.30126208\n  -0.33574797]]\n[[ 2.09152001  2.1243289   2.1243289  ...  2.19006338  2.23933518\n   2.39544025]\n [ 2.86363789  2.8143661   2.78973042 ...  2.74034193  2.74863162\n   2.78144074]\n [ 2.51861907  2.56789087  2.56789087 ...  2.30506965  2.51044608\n   2.51044608]\n ...\n [-0.33972265 -0.33972265 -0.33972265 ... -0.33972265 -0.33972265\n  -0.33972265]\n [-0.50400061 -0.5203466  -0.49571081 ... -0.41363024 -0.41363024\n  -0.40534044]\n [-0.97208167 -0.8489024  -0.77499488 ... -0.8571922  -0.84072941\n  -0.8489024 ]]\n","output_type":"stream"}]}]}